\chapter{Métodos utilizados e Discussão de resultados}
\label{results}
As seções~\ref{dataset} e~\ref{selection} descrevem, respectivamente, o conjunto de dados adquiridos e os atributos que foram previamente selecionados.

Em seguida o capítulo apresenta uma discussão do desempenho obtido pelos classificadores \emph{ensemble}.
\section{Aquisição de códigos fonte}
    \label{dataset}
    O Tile-in-ONE encontra-se em produção, sendo utilizado pelos grupos de calibração e qualidade de dados do TileCal desde 2014. Em seu banco de dados, foram selecionados para este projeto um total de 512 códigos de \emph{Plugins}, desenvolvidos pelos colaboradores através da plataforma web. A figura~\ref{fig:developed_source_codes} ilustra a quantidade de códigos fonte implementados no período de Junho de 2014 a Dezembro de 2015.

    \begin{figure}[H]
      \centering
      \includegraphics[width=17cm]{images/total_source_codes.png}
      \caption{Total de códigos fonte escritos (512) entre Junho/2014 e Dezembro/2015.}
      \label{fig:developed_source_codes}
    \end{figure}

    Dos 512 códigos que compõem o conjunto de dados, quase 30\% não obtiveram sucesso ao serem enviados para uma máquina \emph{slave}. De acordo com a figura~\ref{fig:slave_machine_results}, percebe-se que 8,59\% não retornaram nenhum tipo de resposta para o servidor principal, o que pode significar que a máquina \emph{slave} escolhida para executar o código fonte em questão estava sem comunicação. Isso não significa necessariamente que o código fonte é \emph{não executável}, uma vez que ele nem sequer chegou na máquina \emph{slave}. Os 21,09\% restantes correspondem a programas que falharam durante a tentativa de execução. Mas novamente, não é possível afirmar neste momento que tais códigos são \emph{não executáveis}. Se por ventura, algum desses tentou acessar um banco de dados (externo a plataforma) que no momento da execução estava inacessível, a máquina \emph{slave} retornou falha e, neste caso, o problema não foi o código fonte. Talvez no futuro, esse tipo de informação possa se tornar uma entrada para o classificador: caso o código fonte esteja acessando uma fonte externa ele pode ser penalizado.

    \begin{figure}[H]
      \centering
      \includegraphics[width=8cm]{images/slave_machines_results.png}
      \caption{Retornos obtidos após tentativa de executar códigos fonte em máquinas \emph{slave}.}
      \label{fig:slave_machine_results}
    \end{figure}

    Após avaliar os 512 códigos, e comparar com a aplicação do analisador estático (PyLint), percebe-se que 82,02\% dos códigos são \emph{executáveis}, mas em quase 20\% dos casos o PyLint gera algum tipo de alerta. Do restante, menos de 1\% é \emph{não executável} devido a erros de sintaxe em Python, mas podem ser facilmente identificados ao executar o analisador estático. Dos outros quase 17\% \emph{não executáveis}, cerca de 5\% não podem ser identificados apenas com a aplicação do Pylint. A figura~\ref{fig:targets} ilustra esses percentuais.

    \begin{figure}[H]
      \centering
      \includegraphics[width=8cm]{images/targets.png}
      \caption{Percentuais de alvos do conjunto de códigos fonte.}
      \label{fig:targets}
    \end{figure}

    Em suma, a aplicação do analisador estático não é suficiente para classificar um código como \emph{executável} ou \emph{não executável}. Uma ferramenta adicional faz-se necessária.

    \section{Análise de atributos}
    \label{selection}
    A tabela~\ref{tab:initialattributes} descreve os 11 atributos inicialmente extraídos dos códigos fonte disponíveis na base de dados da plataforma Tile-in-ONE. Ao gerar a matriz de correlação entre tais atributos (figura~\ref{fig:initialcorrelation}), percebe-se que os atributos relacionados às medidas e estatísticas de Halstead são fortemente correlacionados. Treinar um modelo de aprendizado de máquina com atributos altamente correlacionados não melhora a performance dos classificadores gerados e pode aumentar o tempo de convergência.

    \begin{figure}[H]
      \centering
      \includegraphics[width=10cm]{images/corr_matrix_11.png}
      \caption{Matriz de correlação dos 11 atributos extraídos inicialmente}
      \label{fig:initialcorrelation}
    \end{figure} 

    O teste $\chi^2$ foi aplicado para entender, dentre os atributos relacionados a Halstead, quais são os dois mais relevantes. Para este teste, os atributos de Halstead mais relevantes são: \emph{Halstead Volume} e \emph{Required Time}. A nova matriz de correlação calculada (figura~\ref{fig:finalattributes}) demonstra que os 6 atributos selecionados (tabela~\ref{tab:finalattributes}) são suficientemente independentes entre si (com exceção das medidas de Halstead). Observa-se ainda a independência dos atributos selecionados com o alvo, como ilustrado na figura~\ref{fig:finalattributes}.

    \begin{table}[]
    \centering
    \caption{Lista de atributos selecionados}
    \label{tab:finalattributes}
    \begin{tabular}{@{}|l|c|l|@{}}
    \toprule
    \multicolumn{1}{|c|}{\textbf{\#}} & \textbf{Atributo}                       & \multicolumn{1}{c|}{\textbf{Descrição}}                            \\ \midrule
    1                                 & Complexidade Ciclomática                & Número de declarações                                              \\ \midrule
    2                                 & Índice de Manutenabilidade              & Corresponde à organização do código                                \\ \midrule
    3                                 & \multicolumn{1}{l|}{Volume de Halstead} & Combinação entre número de linhas e declarações                    \\ \midrule
    4                                 & Tempo de Halstead                       & Tempo estimado para compilar um código                             \\ \midrule
    5                                & LLOC                                    & Número de linhas lógicas                                           \\ \midrule
    6                                & Alertas PyLint                          & \begin{tabular}[c]{@{}l@{}}Verdadeiro se PyLint gerou alertas. \\ Caso contrário, falso\end{tabular}\\ \bottomrule
    \end{tabular}
    \end{table}

    \begin{figure}[H]
      \centering
      \includegraphics[width=10cm]{images/finalattributes.png}
      \caption{Matriz de correlação dos 6 atributos selecionados. As correlações com a saída também são calculadas.}
      \label{fig:finalattributes}
    \end{figure} 

    
    \section{Avaliação dos Classificadores}
    \label{avaliacao} 

Em Física de Altas Energias, é comum encontrar a aplicação de BDT (\emph{Boosted Decision Tree}, ver seção~\ref{bdt}) para identificação de partículas. No Farmilab, por exemplo, as análises para busca de oscilações de neutrinos deu-se por meio de aplicação de BDT~\cite{Roe2005577}. No CERN existem diversos trabalhos utilizando BDT para identificação do partículas (~\cite{1748-0221-10-09-P09018}, ~\cite{Chatrchyan2012284} e ~\cite{JenniferGodfrey2009} por exemplo). Portanto, existe um incentivo natural para a aplicação de métodos \emph{ensemble} com árvores neste projeto contextualizado no ambiente do CERN. Como citado, a popularidade de árvores de decisão na comunidade científica vem da sua fácil compreensão.

    Com os atributos selecionados (seção~\ref{selection}), classificadores em \emph{ensemble} foram treinados. Para todos os casos, o algoritmo base é uma árvore de decisão, gerada previamente. Como saídas, teremos as classes \emph{executável} indicando que provavelmente o código fonte não vai falhar ao ser executado na máquina \emph{slave} ou, caso contrário, \emph{não executável}.

    Antes de dividir o conjunto de dados em subconjuntos de treino (70\%) e teste (30\%), foi necessário replicar o conjunto com alvo \emph{não executável}, devido a desproporção em número de amostras. É importante ressaltar que os mesmos conjuntos de treino e teste foram utilizados para todos os casos. Como medida de incerteza, foi utilizado o erro quadrático médio das 100 iterações realizadas.

    Como avaliação de performance, foram calculados matrizes de confusão e F1-scores. Em análises estatísticas de classificação binária, o F1-score é uma medida de acurácia. Ela considera tanto precisão quanto sensibilidade, como pode ser observado pela fórmula abaixo:

    \begin{center}
    $F1_{score} = 2 . \frac{p . r}{p + r}$ (V)
    \end{center}
    Na fórmula (V) $p$ é precisão e $r$ é sensibilidade (do inglês, \emph{recall}).

    Precisão é o número de verdadeiro positivos dividido pelo número total de resultados positivos. Sensibilidade é o número de verdadeiro positivos dividido pelo número de resultados positivos que deveriam ter sido retornados.

    O F1-score pode ser interpretado como uma média ponderada da precisão e sensibilidade, onde o melhor valor para avaliar a acurácia é 1 e o pior, 0.
    \\ \\
    \textbf{\large{Árvore de decisão}}\\ \\
    O critério \emph{índice gini} para divisão da árvore de decisão foi utilizado. Estipulou-se um tamanho máximo igual a três, a fim de evitar \emph{overfitting}. Segundo a literatura, é esperado que este classificador tenha um desempenho pior quando comparado com os métodos em \emph{ensemble}. Esta árvore foi utilizada como classificador base nos três métodos descritos a seguir. 
    \\ \\
    \textbf{\large{Bagged Trees}}\\ \\
    Utilizando o mesmo conjunto de treino utilizado para treinar o classificador base e, utilizando a árvore de decisão descrita anteriormente, um classificador em \emph{Bagged Tree} foi gerado. No caso, o número de iterações estabelecido é igual a 100. Ou seja, ao final do treinamento, tem-se 100 árvores treinadas. O resultado dá-se por voto majoritário dessas 100 árvores. A cada rodada, 10\% do conjunto de treino foi utilizado como sub-conjunto \emph{boostrap} (o equivalente a cerca de 60 amostras). Isso é o suficiente para garantir que as amostras não sejam repetidas inúmeras vezes, o que mantém a independência dos 100 classificadores gerados pelo método.\\ \\
    \textbf{\large{Random Forest}}\\ \\
    Para o classificador em \emph{Random Forest} os mesmos critérios estabelecidos para treinar o \emph{Bagged Tree} se aplicam. Mas, o que difere os dois métodos é a quantidade de atributos utilizados em cada iteração para treinar uma árvore. Em~\cite{Breiman:2001:RF:570181.570182}, o Breiman avalia que empiricamente, um número de atributos próximo a $\sqrt{N}$ (sendo N o número total de atributos) é suficiente para obter melhor acurácia. No caso abordado nesta dissertação, temos um número de atributos pequeno (e igual a 6), de tal forma que $\sqrt{6} = 2.45$. O número de atributos, então, utilizado para treinar o classificador em \emph{Random Forest} é igual a 3. Como o \emph{OOB error} é calculado a cada iteração, uma análise de relevância de atributos também pode ser extraída durante o treinamento deste classificador.\\ \\
    \textbf{\large{Boosted Decision Trees}}\\ \\
    Apesar deste método permitir treinamento por \emph{cross-validation}, o mesmo procedimento utilizado para treinar os classificadores descritos anteriormente foi utilizado (70\% do conjunto para treino e 30\% para teste). O motivo dessa escolha é permitir que a análise de performance seja mais justa. Existem diversos algoritmos que determinam como os pesos que serão atribuídos às amostras erroneamente classificadas em cada iteração são definidos. No caso, o algoritmo \emph{AdaBoost}~\cite{Freund1997} (do inglês, \emph{Adaptative Boosting}) foi utilizado. Inicialmente, os pesos atribuídos equivalem a 1. A cada iteração o percentual de amostras classificadas de maneira equivocada é calculado e o peso que será atribuído a tais amostras é definido baseado neste percentual. O resultado final dependerá também deste peso calculado a cada iteração.

    A figura~\ref{fig:adaboost_pseudocode} ilustra um pseudo-código extraído de~\cite{Freund1997}. Nela é possível entender como o peso $\beta$ é calculado, e também como o resultado final é obtido.

    \begin{figure}[H]
      \centering
      \includegraphics[width=8cm]{images/bdt_pseudocode.png}
      \caption{Pseudo-código do algoritmo \emph{AdaBoost}}
      \label{fig:adaboost_pseudocode}
    \end{figure} 

    As figuras~\ref{fig:confusionmatrices} e~\ref{fig:reports} 
    ilustram as matrizes de confusão e algumas medidas de desempenho, respectivamente, que foram geradas utilizando o mesmo conjunto de teste para os 4 classificadores gerados.

    No caso da árvore de decisão, é esperado que seu desempenho seja pior comparativamente: o tamanho fixado em três e o número máximo de folhas fixado em cinco impede que ao final, o classificador gerado possua folhas mais puras. A vantagem dessa abordagem é que desta maneira, é mais difícil obter \emph{overfitting}. Por outro lado, uma árvore de decisão é insuficiente para se obter generalização.

    Tais questões são contornadas com a aplicação dos métodos \emph{ensemble}, como previsto na teoria. Dos classificadores gerados por tal método, obtém-se melhor desempenho com o BDT para a classe \emph{não executável}. Percebe-se que o número de iterações estabelecido em 100 já é suficiente para atingir tal desempenho. Como ilustrado na figura~\ref{fig:reportbdt}, o classificador em BDT apresenta cerca de 90\% para precisão e sensibilidade nas duas classes (\emph{executável} e \emph{não executável}).

    O classificador \emph{Bagged Trees} é capaz de melhorar um pouco a classificação quando comparado com a árvore de decisão gerada. Isto também está coerente com a teoria. Gerar 100 árvores de decisão com sub-conjuntos diferentes aumenta a diversidade dos 70\% do conjunto de treino. Tal procedimento é comparável ao treinamento por \emph{cross-validation}. Isso explica o melhor desempenho deste classificador quando comparado com a árvore de decisão treinada.

    Além da variação ocorrida no treinamento para gerar o classificador \emph{Bagged Trees}, o \emph{Random Forest} varia também a quantidade de atributos utilizados no momento do treinamento das 100 árvores de decisão em cada iteração. Esse fato, além de melhorar o desempenho da classificação, permite que uma avaliação de atributos mais relevantes seja feita. Em outras palavras, a cada árvore gerada é possível obter o erro \emph{OOB} e, avalia-lo de acordo com os atributos que participaram daquela iteração. A figura~\ref{fig:randomforestfeatures} ilustra através de um gráfico de barras quais são os atributos mais relevantes dos 6 (listados na tabela~\ref{tab:finalattributes}) utilizados para o treinamento da \emph{Random Forest}. É possível perceber que o índice de manutenabilidade é o atributo que mais contribui para o treinamento do classificador. A complexidade ciclomática chega a ser menos relevante até que as medidas de Halstead.

    A tabela~\ref{tab:summary} apresenta as medidas de desempenho dos 4 classificadores gerados. Nela é possível identificar o melhor desempenho pelo F1-score do BDT sob os demais classificadores.

    \begin{figure}[!ht]
      \centering
      \mbox{
        \subfigure[Árvore de Decisão]{
           \includegraphics[width=6.5cm]{images/cm_dt.png}
           \label{fig:cmdt}
        }
        \subfigure[Bagged Trees]{
          \includegraphics[width=6.5cm]{images/cm_bagged.png}
          \label{fig:cmbagged}
        }
      }
      \mbox{
        \subfigure[Random Forest]{
          \includegraphics[width=6.5cm]{images/cm_randomforest.png}
          \label{fig:cmrandomforest}
        }
        \subfigure[Boosted Decision Trees]{
           \includegraphics[width=6.5cm]{images/cm_bdt.png}
           \label{fig:cmbdt}
        }
      }
      \caption{Matrizes de Confusão dos 4 classificadores gerados.}
      \label{fig:confusionmatrices}
    \end{figure}

    \begin{figure}[!ht]
      \centering
        \subfigure[Árvore de Decisão]{
           \includegraphics[width=12cm]{images/report_dt.png}
           \label{fig:reportdt}
        }
        \subfigure[Bagged Trees]{
          \includegraphics[width=12cm]{images/report_bagged.png}
          \label{fig:reportbagged}
        }
      
        \subfigure[Random Forest]{
          \includegraphics[width=12cm]{images/report_randomforest.png}
          \label{fig:reportrandomforest}
        }
        \subfigure[Boosted Decision Trees]{
           \includegraphics[width=12cm]{images/report_bdt.png}
           \label{fig:reportbdt}
        }
      \caption{Medidas de desempenho dos 4 classificadores gerados.}
      \label{fig:reports}
    \end{figure}

    \begin{figure}[H]
      \centering
      \includegraphics[width=10cm]{images/randomforest_features.png}
      \caption{Atributos mais relevantes de acordo com erro OOB}
      \label{fig:randomforestfeatures}
    \end{figure}

    % Please add the following required packages to your document preamble:
% \usepackage{booktabs}
% \usepackage{multirow}

\begin{landscape}
\begin{table}[]
\centering
\caption{Resumo das medidas de desempenho dos 4 classificadores gerados}
\label{tab:summary}
\begin{tabular}{@{}|c|c|c|c|c|c|c|@{}}
\toprule
\multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Classificador /\\ Classes\end{tabular}}} & \multicolumn{2}{c|}{\textbf{Precisão (Precision)}}                    & \multicolumn{2}{c|}{\textbf{Sensibilidade (Recall)}}                  & \multicolumn{2}{c|}{\textbf{F1-Score}}                                \\ \cmidrule(l){2-7} 
                                                                                              & \multicolumn{1}{l|}{Executável} & \multicolumn{1}{l|}{Não executável} & \multicolumn{1}{l|}{Executável} & \multicolumn{1}{l|}{Não executável} & \multicolumn{1}{l|}{Executável} & \multicolumn{1}{l|}{Não executável} \\ \midrule
\textbf{Árvore de Decisão}                                                                    & 0,71 (0,03)                           & 0,92 (0,09)                               & 0,96 (0,04)                            & 0,54 (0,13)                                & 0,81 (0,03)                           & 0,64 (0,11)                                \\ \midrule
\textbf{Bagged Trees}                                                                         & 0,76 (0,02)                           & 0,88 (0,05)                               & 0,92 (0,03)                           & 0,67 (0,12)                               & 0,83 (0,02)                           & 0,76 (0,07)                               \\ \midrule
\textbf{Random Forest}                                                                        & 0,90 (0,01)                            & 0,86 (0,03)                               & 0,87 (0,01)                            & 0,89 (0,01)                               & 0,89 (0,01)                           & 0,87 (0,02)                               \\ \midrule
\textbf{Boosted Decision Trees}                                                                & 0,92 (0,01)                           & 0,89 (0,02)                               & 0,90 (0,03)                           & 0,91 (0,01)                               & \textbf{0,91 (0,02)}                   & \textbf{0,90 (0,01)}                       \\ \bottomrule
\end{tabular}
\end{table}
\end{landscape}