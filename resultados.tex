\chapter{Resultados}
Este capítulo apresenta o desempenho obtido pelos classificadores \emph{ensemble} descritos no capítulo anterior.

Foram gerados, ao todo, 4 classificadores e a comparação dos resultados é feita através de matrizes de confusão e F1-score. A base de dados é composta por códigos submetidos através da plataforma web Tile-in-ONE. Inicialmente, foi necessário fazer o balanceamento das amostras. Além disso, 70\% do conjunto foi separado para treino e 30\% para teste. Alguns dos métodos não permite treinamento por \emph{cross-validation} e para uma avaliação justa, a mesma metodologia foi aplicada em todos os treinamentos.
\label{resultados}
    \section{Avaliação dos Classificadores}
    \label{avaliacao} 
    As figuras~\ref{fig:confusionmatrices} e~\ref{fig:reports} ilustram as matrizes de confusão e algumas medidas de desempenho, respectivamente, que foram geradas utilizando o mesmo conjunto de teste para os 4 classificadores gerados.

    No caso da árvore de decisão, é esperado que seu desempenho seja pior comparativamente: o tamanho fixado em três e o número máximo de folhas fixado em cinco impede que ao final, o classificador gerado possua folhas mais puras. A vantagem dessa abordagem é que desta maneira, é mais difícil obter \emph{overfitting}. Por outro lado, uma árvore de decisão é insuficiente para se obter generalização.

    Tais questões são contornadas com a aplicação dos métodos \emph{ensemble}, como previsto na teoria. Dos classificadores gerados por tal método, obtém-se melhor desempenho com o BDT, mesmo que o treinamento não seja feito por \emph{cross-validation}. Percebe-se que o número de iterações estabelecida em 100 já é suficiente para atingir tal desempenho. Como ilustrado na figura~\ref{fig:reportbdt}, o classificador apresenta cerca de 90\% para precisão e sensibilidade nas duas classes (\emph{executável} e \emph{não executável}).

    O classificador \emph{Bagged Trees} é capaz de melhorar um pouco a classificação quando comparado com a árvore de decisão gerada. Isto também está coerente com a teoria. Gerar 100 árvores de decisão com sub-conjuntos diferentes aumenta a diversidade dos 70\% do conjunto de treino. Tal procedimento é comparável ao treinamento por \emph{cross-validation}. Isso explica o melhor desempenho deste classificador quando comparado com a árvore de decisão treinada.

    Além da variação ocorrida no treinamento para gerar o classificador \emph{Bagged Trees}, o \emph{Random Forest} varia também a quantidade de atributos utilizados no momento do treinamento das 100 árvores de decisão em cada iteração. Esse fato, além de melhorar o desempenho da classificação, permite que uma avaliação de atributos mais relevantes seja feita. Em outras palavras, a cada árvore gerada é possível obter o erro \emph{OOB} e, avalia-lo de acordo com os atributos que participaram daquela iteração. A figura~\ref{fig:randomforestfeatures} ilustra através de um gráfico de barras quais são os atributos mais relevantes dos 6 (listados na tabela~\ref{tab:finalattributes}) utilizados para o treinamento da \emph{Random Forest}. É possível perceber que o índice de manutenabilidade é o atributo que mais contribui para o treinamento do classificador. A complexidade ciclomática chega a ser menos relevante até que as medidas de Halstead.

    A tabela~\ref{tab:summary} apresenta as medidas de desempenho dos 4 classificadores gerados. Nela é possível identificar o melhor desempenho pelo F1-score do BDT sob os demais classificadores.

    \begin{figure}[!ht]
      \centering
      \mbox{
        \subfigure[Árvore de Decisão]{
           \includegraphics[width=6.5cm]{images/cm_dt.png}
           \label{fig:cmdt}
        }
        \subfigure[Bagged Trees]{
          \includegraphics[width=6.5cm]{images/cm_bagged.png}
          \label{fig:cmbagged}
        }
      }
      \mbox{
        \subfigure[Random Forest]{
          \includegraphics[width=6.5cm]{images/cm_randomforest.png}
          \label{fig:cmrandomforest}
        }
        \subfigure[Boosted Decision Trees]{
           \includegraphics[width=6.5cm]{images/cm_bdt.png}
           \label{fig:cmbdt}
        }
      }
      \caption{Matrizes de Confusão dos 4 classificadores gerados.}
      \label{fig:confusionmatrices}
    \end{figure}

    \begin{figure}[!ht]
      \centering
        \subfigure[Árvore de Decisão]{
           \includegraphics[width=12cm]{images/report_dt.png}
           \label{fig:reportdt}
        }
        \subfigure[Bagged Trees]{
          \includegraphics[width=12cm]{images/report_bagged.png}
          \label{fig:reportbagged}
        }
      
        \subfigure[Random Forest]{
          \includegraphics[width=12cm]{images/report_randomforest.png}
          \label{fig:reportrandomforest}
        }
        \subfigure[Boosted Decision Trees]{
           \includegraphics[width=12cm]{images/report_bdt.png}
           \label{fig:reportbdt}
        }
      \caption{Medidas de desempenho dos 4 classificadores gerados.}
      \label{fig:reports}
    \end{figure}

    \begin{figure}[H]
      \centering
      \includegraphics[width=10cm]{images/randomforest_features.png}
      \caption{Atributos mais relevantes de acordo com erro OOB}
      \label{fig:randomforestfeatures}
    \end{figure}

    % Please add the following required packages to your document preamble:
% \usepackage{booktabs}
% \usepackage{multirow}

\begin{landscape}
\begin{table}[]
\centering
\caption{Resumo das medidas de desempenho dos 4 classificadores gerados}
\label{tab:summary}
\begin{tabular}{@{}|c|c|c|c|c|c|c|@{}}
\toprule
\multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Classificador /\\ Classes\end{tabular}}} & \multicolumn{2}{c|}{\textbf{Precisão (Precision)}}                    & \multicolumn{2}{c|}{\textbf{Sensibilidade (Recall)}}                  & \multicolumn{2}{c|}{\textbf{F1-Score}}                                \\ \cmidrule(l){2-7} 
                                                                                              & \multicolumn{1}{l|}{Executável} & \multicolumn{1}{l|}{Não executável} & \multicolumn{1}{l|}{Executável} & \multicolumn{1}{l|}{Não executável} & \multicolumn{1}{l|}{Executável} & \multicolumn{1}{l|}{Não executável} \\ \midrule
\textbf{Árvore de Decisão}                                                                    & 0.71                            & 0.92                                & 0.96                            & 0.54                                & 0.81                            & 0.64                                \\ \midrule
\textbf{Bagged Trees}                                                                         & 0.76                            & 0.88                                & 0.92                            & 0.67                                & 0.83                            & 0.76                                \\ \midrule
\textbf{Random Forest}                                                                        & 0.90                            & 0.86                                & 0.87                            & 0.89                                & 0.89                            & 0.87                                \\ \midrule
\textbf{Boosted Decision Trees}                                                                & 0.92                            & 0.89                                & 0.90                            & 0.91                                & \textbf{0.91}                   & \textbf{0.90}                       \\ \bottomrule
\end{tabular}
\end{table}
\end{landscape}

    \section{Análise de \emph{Misclassifieds}}
    \label{misclassified}