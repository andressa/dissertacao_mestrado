\chapter{Mineração de códigos fonte para identificação de falhas}
\label{code_mining}
Em desenvolvimento de software é comum observar que quanto maior for o tempo de permanência de um erro no código mais custosa torna-se a sua correção e manutenção em um projeto~\cite{IEEE-Software-McConnel}. Falhas em códigos fonte são definidas como ``Imperfeições durante o desenvolvimento de software que como consequência impedem que o programa atinja as expectativas desejadas."~\cite{BASKARAN2010}. Entende-se ainda que muitos defeitos são introduzidos durante o processo de desenvolvimento como um todo, não somente no seu início ou fim. Assim sendo, identificar falhas antecipadamente torna-se parte essencial em desenvolvimento de software, que significa qualidade na entrega final do produto.~\cite{ODC1992}.

O SDLC (do inglês, \emph{software development life cycle} ou ciclo de vida do desenvolvimento de software)~\cite{6906040} indica que o desenvolvimento de software pode ser descrito em cinco etapas:
\begin{enumerate}
  \item{Levantamento de Requisitos}
  \item{Projeto}
  \item{Implementação}
  \item{Teste}
  \item{Implantação}
\end{enumerate}

A figura~\ref{fig:bug_insertion} ilustra em quais etapas do ciclo de vida de desenvolvimento do software são inseridos. Entidades presentes na área de engenharia de computação (tais como a IBM~\cite{IBM} e HCL~\cite{HCL}) confirmam que cerca de 35\% das falhas identificadas em códigos fonte são inseridas na fase de implementação~\cite{CODEMINING2015}.

\begin{figure}[h]
  \centering
  \includegraphics[width=8cm]{images/bug_insertion_sdlc.png}
  \caption{Estimativa do percentual de erros inseridos durante fases do SDLC. (Fonte: \emph{Computer Finance Magazine}. Dados extraídos de~\cite{CODEMINING2015})}
  \label{fig:bug_insertion}
\end{figure}

Atualmente, diferentes técnicas tem sido utilizadas para identificação antecipada de erros em códigos fonte. A análise estática, por exemplo, é bastante utilizada na área de programação desde a década de 80. As características desta análise são abordadas em~\ref{static_analysis}. Em conjunto com analisadores estáticos, pode-se aplicar técnicas de mineração de dados, fazendo uma combinação entre a área de engenharia de software e inteligência computacional. No artigo~\cite{4222731}, publicado em 2007, os autores abordam como a mineração de dados pode contribuir com a área de engenharia de software, a medida que técnicas de inteligência computacional, quando aplicadas, melhoram a qualidade de projetos. Nesta mesma direção, a MSR (em inglês, \emph{Mining Software Repositories} ou mineração de repositórios de códigos) passa a ser amplamente abordada devido a disponibilidade gratuita de inúmeros repositórios públicos de controle de versionamento, rastreamento de erros inseridos e até mesmo documentações~\cite{4659248}.

Aplicar mineração de dados em códigos fonte desperta interesse na comunidade científica, uma vez que códigos são tipicamente estruturados e semanticamente ricos em termos de construtores de programação (tais como variáveis, funções, objetos estruturados e rotinas bem definidas). Os objetivos são diversos: vão desde a tentativa de descobrir o que um determinado software faz (sem necessariamente executá-lo) até manutenção de projetos ou análises de desenvolvimento~\cite{130589}.

Como citado, a identificação antecipada de erros inseridos durante a implementação de códigos fonte é atraente do ponto de vista de qualidade de produto. A utilização de mineração de códigos é uma das aplicações mais ativas em engenharia de software atualmente. Neste caso, o objetivo é obter ferramentas que não só identifiquem falhas (ou \emph{bugs}) mas também sua localização exata nas linhas de códigos do projeto, de tal forma que o seu conserto seja facilitado~\cite{130589}. Para alcançar esse objetivo, uma direção de bastante destaque consiste na mineração de padrões, que uma vez pré-definidos, são aplicadas em diversos repositórios de projetos já existentes com o objetivo de encontrar anomalias comuns que violam regras (~\cite{Li05pr-miner:automatically},~\cite{4222586},~\cite{Chang:2007:FWN:1273463.1273486}).

Outro objetivo dominante na mineração de códigos é a tentativa de identificar fragmentos clonados. A não reutilização de códigos dificulta a manutenção do software e ainda, pode proliferar \emph{bugs} em diferentes partes de um projeto.

A seção~\ref{code_mining_cern} investiga a aplicação de mineração de dados em códigos fonte no CERN; A seção~\ref{categories} aborda quais são os atributos comumente utilizados quando mineração de dados é aplicada em códigos fonte. Esta seção é composta por duas sub-seções (~\ref{static_analysis} e~\ref{halstead}) que abordam em que situações tais atributos foram utilizados na aplicação de mineração de códigos neste contexto;  Por fim, a seção~\ref{ensemble} descreve métodos de aprendizado de máquina que foram utilizados neste mestrado na tentativa de classificar de códigos fonte em \emph{executáveis/não executáveis}.

\section{Analisadores estáticos e Mineração de códigos no CERN}
    \label{code_mining_cern}
    O CERN oferece um ambiente para desenvolvimento de software bastante particular. Estima-se que centenas de projetos de software estão sendo desenvolvidos, com propósitos específicos, desde programas que auxiliam o trabalho da equipe de recursos humanos até os que monitoram o desempenho dos diversos experimentos do colisor de partículas. Apesar do setor de TI do CERN ter estipulado algumas regras para a política de segurança, muitos projetos de software pequenos não as seguem a risca. Isso implica em vulnerabilidades de programas utilizados em ambientes de produção no CERN.

    As regras de segurança estipuladas não são tão rígidas para estimular o meio acadêmico no avanço das pesquisas científicas. Da mesma maneira, analisadores estáticos para assegurar a qualidade no desenvolvimento de códigos livres não são impostos para a comunidade presente. Existem ferramentas disponíveis e com documentação e suporte da equipe de TI, mas nenhum projeto é obrigado a utilizá-las. No caso deste projeto de mestrado, a linguagem computacional utilizada é o Python, sendo o \emph{PyLint}~\cite{pylint} uma ferramenta de análise estática cuja utilização é incentivada pelo CERN~\cite{cern_recomendations_tools}.

    Recentemente, o setor de segurança em computação do CERN contratou um serviço (\emph{Coverity}~\cite{Bessey:2010:FBL:1646353.1646374}) para garantir qualidade no desenvolvimento de novas funcionalidades no seu principal produto de análises físicas (o ROOT~\cite{BRUN}). O ROOT é utilizado por cerca de 10.000 pesquisadores e a integridade do software passou a ser vista como algo valioso. Um \emph{bug} perpetuado no ROOT pode ter um impacto muito negativo nas análises de resultados dos dados gerados pelo LHC. Assim que incorporado, o \emph{Coverity} já foi capaz de identificar mais de 40.000 falhas em aproximadamente 50 milhões de linhas de códigos~\cite{coverity_numbers}. Um ponto negativo observado por desenvolvedores do ROOT é o tempo necessário para executar o analisador estático: são 28 horas para cada 2 milhões de linhas de código. É válido observar que a ferramenta escolhida para o ROOT não atende as necessidades deste projeto de mestrado: o \emph{Coverity} atende códigos escritos em linguagem C/C++ enquanto os códigos do Tile-in-ONE (seção~\ref{tio}) são implementados em Python. Além disso, deseja-se aplicar mineração de dados em códigos fonte em um ambiente web.

    Em física de altas energias não existem artigos que indiquem a aplicação de mineração de dados em códigos fonte.


    \section{Escolha de atributos}
    \label{categories}
    Uma revisão feita por Heckman~\cite{Heckman:2011:SLR:1945085.1945215} com 21 artigos sobre mineração de dados em códigos fonte, identifica cinco categorias comumente utilizadas como atributos:
    \begin{enumerate}
      \item{\emph{Alert Characteristics} (AC): abordagem que leva em consideração os alertas gerados por analisadores estáticos (sub-seção~\ref{static_analysis});}
      \item{\emph{Code Characteristics} (CC): abordagem que considera medidas estatísticas e de qualidade do código fonte como atributos de entrada para algoritmos de máquina de aprendizado(sub-seção~\ref{halstead});}
      \item{\emph{Source code repository metrics} (SCR): atributos retirados de repositórios de códigos. Nesta abordagem, leva-se em consideração versionamentos (histórico de \emph{bugs} inseridos no projeto), comentários de atualizações e documentação sobre requisitos por exemplo;}
      \item{\emph{Bug database metrics} (BDM): Neste caso, existe uma base de dados para o projeto contendo todos as falhas já surgidas e consertadas. O objetivo dessa abordagem é identificar padrões que podem voltar a acontecer no projeto;}
      \item{\emph{Dynamic analyses metric} (DA): esta abordagem armazena resultados obtidos com análise dinâmica de códigos, mediante diversas execuções (ver seção~\ref{static_analysis})}.
    \end{enumerate}

    Tais categorias são descritas detalhadamente em~\cite{Heckman:2008}.

    Este mestrado utiliza as duas primeiras abordagens, descritas nas próximas sub-seções.

        \subsection{Analisadores Estáticos}
        \label{static_analysis}

        Em engenharia de software existem dois tipos de análise (complementares) que podem ser feitas para validar e testar o produto em concepção~\cite{1646907}:
        \begin{itemize}
          \item{\textbf{Estática}: neste caso apenas a estrutura do código é analisada, mas o código não é executado;
          }
          \item{\textbf{Dinâmica}: para esta análise, é preciso levantar um plano de testes, executá-los e avaliar os resultados. Ou seja, é necessário executar o código diversas vezes;
          }
        \end{itemize}

        Como o objetivo deste mestrado é analisar códigos fonte sem executá-los,  utilizar analisadores estáticos torna-se atraente, por definição.

        Na década de 80, diversas ferramentas que aplicam análise estática de código começaram a ser desenvolvidas para auxiliar desenvolvedores na implementação de códigos com menos \emph{bugs}~\cite{Tischler:1983:SAP:1006140.1006182}. Mas logo um inconveniente surge~\cite{YukselS13}: a quantidade de alertas gerados pelas ferramentas de análise estática de código (SCAT, do inglês, \emph{Static Code Analysis Tools}) é grande e muitos deles não são acionáveis. Diz-se acionável um alerta que realmente vai impedir o sucesso na execução de um determinado código. Essa classificação é feita manualmente pelo desenvolvedor (que neste caso é o especialista): se o especialista entende que determinado alerta é importante e precisa ser consertado antes da execução do programa, tal alerta é definido como \emph{acionável}. Caso contrário, ele é definido como \emph{não acionável}(~\cite{4815348},~\cite{Heckman:2008:EBE:1414004.1414013}).

        Empiricamente, existem cerca de 40 alertas para cada mil linhas de código (KLOC, do inglês, \emph{Kilo Lines of Code})~\cite{Heckman:2008:EBE:1414004.1414013}. Desta estimativa, podem ser não acionáveis 30-100\%, como observado em~\cite{Aggarwal:2006:ISD:1169228.1170032},~\cite{4026864},~\cite{Heckman:2008:EBE:1414004.1414013},~\cite{4228664},~\cite{Kim:2007:WIF:1287624.1287633},~\cite{Kremenek:2003:ZUS:1760267.1760289}. Tais números desestimulam desenvolvedores e projetistas a aplicar ferramentas de análise estática de código no processo de desenvolvimento de software, embora entende-se a sua importância no quesito qualidade adquirida. Por outro lado, um alerta definido pelo especialista como \emph{acionável} nem sempre vai impedir a execução bem sucedida do código. Ou seja, se por um lado os analisadores estáticos geram muitos alertas (\emph{não acionáveis}), nada garante que o alerta \emph{acionável} indica que o programa contém \emph{bugs} e vai falhar durante a tentativa de execução. Em outras palavras, um analisador estático pode não gerar nenhum alerta e mesmo assim, durante a tentativa de execução, o código ainda pode falhar.

        Para este mestrado, um dos atributos utilizados corresponde a geração ou não de alertas pelo analisador estático. Adicionalmente, outras medidas estatísticas e de qualidade, descritas a seguir, compõem a lista inicial de atributos extraídos de códigos fonte(tabela~\ref{tab:initialattributes}).

        \subsection{Medidas estatísticas e de qualidade}
        \label{halstead}

        Em computação, ``Halstead Metrics''~\cite{Halstead:1977:ESS:540137} são medidas de qualidade e estatísticas definidas por Maurice Halstead e publicadas em 1977.

        As medidas estatísticas (de Halstead) que podem ser extraídas de um código fonte são:
        \begin{itemize}
          \item{$\eta_1$: quantidade de operadores distintos no código;}
          \item{$\eta_2$: quantidade de operandos distintos no código;}
          \item{$N_1$: total de operadores;}
          \item{$N_2$: total de operandos;}
        \end{itemize}

        Destas, outras medidas estatísticas são também definidas por Halstead:
        \begin{itemize}
          \item{Vocabulário: $\eta = \eta_1 + \eta_2$;}
          \item{Tamanho: $N = N_1 + N_2$;}
          \item{Volume: $V = N log_2 \eta$;}
          \item{Dificuldade: $D = \frac{\eta_1}{2} . \frac{N_2}{\eta_2}$;}
          \item{Esforço: $E = D . V$;}
          \item{Estimativa de tempo de execução (em segundos): $ T = \frac{E}{18}$;}
          \item{Estimativa de potenciais \emph{bugs}: $ B = \frac{V}{3000} $};
        \end{itemize}

        Outra característica que pode ser extraída de códigos fonte é a sua complexidade. Define-se como ``Cyclomatic Complexity'' (do inglês, complexidade ciclomática)~\cite{maccabe1983structured} o número de decisões que um determinado bloco de código contém mais uma unidade. Este número (também conhecido como \emph{McCabe number}) representa o número de caminhos independentes percorridos durante a execução de um código, quando se monta uma árvore abstrata de sintaxe (AST, do inglês, \emph{abstract syntax tree})~\cite{jones03pattern}.

        O índice de manutenabilidade (ou MI, do inglês \emph{Maintainability Index}) é uma medida em software que indica o quão fácil é a manutenção de um determinado código. O MI é calculado de diferentes maneiras, dependendo da abordagem que se deseja utilizar. Entretanto, a fórmula clássica~\cite{242525} envolve o número de linhas totais em um código fonte (SLOC, do inglês, \emph{source lines of code}), a complexidade ciclomática (neste contexto, CC) e o volume de Halstead (HV): \\ $MI = 171 - 5.2 ln _{HV} - 0.23 _{CC} - 16.2 ln _{SLOC}$.\\Os autores chegaram nesta fórmula através de um número de códigos fornecidos pela HP, escritos em linguagens de programação C e Pascal. Para cada código, um especialista (engenheiro de software) atribuiu uma nota (de 1 a 100) indicando o quão fácil seria fazer alterações ou correções posteriores ao determinado código (quanto maior a nota, mais fácil é sua manutenção). Consequentemente, 40 faixas de valores foram identificadas e através de uma regressão estatística, eventualmente, a fórmula exposta foi encontrada como um índice de manutenabilidade. Existe ainda o LLOC (do inglês, \emph{Logic Lines of Code}), que indica a quantidade de linhas com operadores lógicos no código e é outra medida que pode ser extraída como um atributo de códigos fonte.

        A tabela~\ref{tab:initialattributes} lista os atributos inicialmente extraídos e uma breve descrição. Uma análise de relevância e correlação foi realizada. Os resultados são apresentados na seção~\ref{selection}.
        
    \begin{table}[]
    \centering
    \caption{Lista inicial de atributos}
    \label{tab:initialattributes}
    \begin{tabular}{@{}|l|c|l|@{}}
    \toprule
    \multicolumn{1}{|c|}{\textbf{\#}} & \textbf{Atributo}                       & \multicolumn{1}{c|}{\textbf{Descrição}}                            \\ \midrule
    1                                 & Complexidade Ciclomática                & Número de declarações                                              \\ \midrule
    2                                 & Índice de Manutenabilidade              & Corresponde à organização do código                                \\ \midrule
    3                                 & Vocabulário de Hasltead                 & \# de operadores + \# de operandos únicos                          \\ \midrule
    4                                 & Tamanho de Halstead                     & \# de operadores + \# total de operandos                           \\ \midrule
    5                                 & SLOC                                    & Número de linhas do código fonte                                   \\ \midrule
    6                                 & \multicolumn{1}{l|}{Volume de Halstead} & Combinação entre número de linhas e declarações                    \\ \midrule
    7                                 & Dificuldade de Hasltead                 & \begin{tabular}[c]{@{}l@{}}Complexidade do código baseada no número de \\ operadores e operandos\end{tabular} \\ \midrule
    8                                 & Tempo de Halstead                       & Tempo estimado para compilar um código                             \\ \midrule
    9                                 & Bugs de Halstead                        & Possibilidade de bugs serem gerados                                \\ \midrule
    10                                & LLOC                                    & Número de linhas lógicas                                           \\ \midrule
    11                                & Alertas PyLint                          & \begin{tabular}[c]{@{}l@{}}Verdadeiro se PyLint gerou alertas. \\ Caso contrário, falso\end{tabular}\\ \bottomrule
    \end{tabular}
    \end{table}

    \section{Métodos \emph{ensemble} em Árvores de Decisão}
    \label{ensemble}
    Árvore de decisão (DT, do inglês, \emph{Decision Tree})~\cite{Rokach:2008:DMD:1796114} é um algoritmo de aprendizado de máquina supervisionado. O termo ``supervisionado'' indica que, durante a fase de treinamento, as classes (ou alvos) são conhecidas. Desta maneira, o classificador aprende com casos em que se sabe a resposta (\emph{executável}/\emph{não executável}).

    Basicamente, o treinamento de uma árvore de decisão divide e agrupa o conjunto de treino em dois ou mais grupos homogêneos, sucessivamente. Para as divisões, o algoritmo se encarrega de escolher qual é o atributo mais significativo, ou seja, qual atributo irá tornar a divisão o mais homogênea (ou pura) possível. Tal processo consiste no que se conhece como \emph{splitting} e será descrito mais adiante nesta seção.

    A figura[XXX] ilustra um exemplo clássico de árvore de decisão. Ele representa uma árvore que decide se uma pessoa vai ou não jogar tênis. Os atributos utilizados são condições do tempo (ensolarado, nublado ou chuvoso), umidade (alta ou baixa) e vento (forte ou fraco).

    Ainda sobre a figura[XXX], o conhecimento de algumas nomenclaturas é necessário. Elas serão referenciadas mais adiante. São elas:
    \begin{itemize}
        \item{O nó raiz (representado pela cor azul) representa todo o conjunto de treino e é onde as divisões em grupos heterogêneos começa.}
        \item{Os nós que continuam dividindo os sub-conjuntos restantes (em cinza) são denominados nós de decisão.}
        \item{Quando a divisão cessa, tem-se folhas (em verde). As folhas indicam a decisão tomada pela árvore treinada.}
    \end{itemize}

    Existem duas operações relacionadas ao treinamento de árvores de decisão. Elas estão descritas a seguir.

    \large{\emph{Splitting}}\\
    \large{\emph{Pruning}}\\

    Uma das vantagens em se utilizar árvores de decisão para classificação é a sua fácil compreensão. Para pessoas sem conhecimentos em inteligência computacional, o treinamento de classificadores e os resultados obtidos são de fácil compreensão. Além disso, a representação gráfica é intuitiva e permite que hipóteses sejam rapidamente relacionadas.

    Entretanto, existe uma desvantagem que faz com que árvores de decisão não sejam consideradas classificadores fortes: o fato de dividir conjuntos em sub-conjuntos homogêneos faz com que o classificador gerado fique especialista no conjunto de treino (\emph{overfit}). Ou seja, a árvore gerada sempre dependerá do conjunto de treino utilizado. O método \emph{ensemble} contorna essa questão levantada.

    \emph{Ensemble} são conjuntos de classificadores que combinam seus resultados individuais (por votação ou média ponderada) para classificar novas amostras~\cite{Seni:2010:EMD:1841412}. Uma das áreas mais ativas na área de aprendizado de máquina supervisionado tem sido \emph{ensemble}~\cite{Dietterich:2000:EMM:648054.743935}. Geralmente, classificadores \emph{ensemble} apresentam maior acurácia que classificadores individuais. A razão estatística para isso é que a variância de um somatório é menor que a variância individual. Computacionalmente, o treinamento pode dar-se de maneira mais rápida, uma vez que, em alguns casos é possível paralelizar a fase de treinamento.

    Classificadores \emph{ensemble} podem ser gerados para qualquer algoritmo, inclusive árvores de decisão. Tais classificadores são descritos nas sub-seções a seguir.

    \subsection{Bagged Trees (\emph{\textbf{B}ootstrap \textbf{Agg}regating})}
    \label{bagged}

    Apesar do nome, \emph{Bagged Trees} pode ser utilizado com qualquer algoritmo base. Neste tipo de \emph{ensemble}, um sub-conjunto com N elementos do conjunto de treino é selecionado para o treinamento de um classificador. Em seguida, um novo sub-conjunto com outros N elementos é utilizado para gerar um outro classificador. Esse procedimento é repetido, até que um número total e pré-definido de classificadores seja gerado. A classificação final dá-se por voto majoritário. A figura~\ref{fig:bagged_pseudocode} ilustra um pseudo-código que descreve como \emph{Bagged Trees} é treinado e utilizado para classificações.

    \begin{figure}[htbp]
      \centering
        \includegraphics[width=9.0cm]{images/bagged_pseudocode.png}
        \caption{\emph{Bagged Trees} pseudo-código. Retirado de ~\cite{Rokach:2008:DMD:1796114}.}
      \label{fig:bagged_pseudocode}
    \end{figure}

    \subsection{Random Forest}
    \label{randomforest}
    Alguns autores consideram \emph{Random Forest} como uma variação de \emph{Bagged Trees}~\cite{Dietterich:2000:EMM:648054.743935}. Este classificador \emph{ensemble} é apresentado por Breiman em~\cite{Breiman:2001:RF:570181.570182}.

    A primeira diferença é que \emph{Random Forest} só utiliza árvores de decisão como algoritmo base. Outra diferença entre os dois algoritmos é a quantidade de atributos utilizados durante o treinamento dos classificadores: neste caso, nem todos os atributos são utilizados. Escolhe-se a quantidade de atributos que será utilizada e a cada nova árvore, um sub-conjunto diferente de atributos é utilizado. Isso permite analisar a contribuição de cada atributo no treinamento de cada árvore.

    O termo \emph{Out of Bag (OOB)} também é introduzido por Breiman. Assim, tem-se uma nova medida para erro: cerca de um terço do conjunto de treino é separada e utilizada a cada rodada como um conjunto de teste. É a partir desta medida que a análise de contribuição dos atributos torna-se possível.

    Similar ao \emph{Bagged Trees}, o resultado final dá-se por voto majoritário.

    \subsection{Boosted Decision Trees (BDT)}
    \label{bdt}
    Este é outro algoritmo \emph{ensemble} que não exige apenas árvores de decisão como classificador base. Diferentemente dos casos anteriores, todo o conjunto de treino é utilizado para gerar o classificador. Mas, a cada rodada, verifica-se quais amostras foram erroneamente classificadas e atribui-se um peso a elas. Desta maneira, na próxima iteração, os casos equivocados estarão evidenciados. A figura~\ref{fig:bdt_example} ilustra o que ocorre com o conjunto de treino a cada rodada: dadas duas classes, verde e vermelha, ao gerar o primeiro classificador, temos 3 amostras erroneamente classificadas (\emph{misclassifieds}). Em outras palavras, temos 3 amostras que pertencem a classe verde, mas o classificador gerado atribuiu a classe vermelha a elas. Em uma próxima iteração, tais amostras serão multiplicadas por um fator que influenciará o treinamento. O resultado final ocorre por voto majoritário.

    É interessante observar na figura~\ref{fig:bdt_result} que a combinação de diversos classificadores gera um classificador refinado.

    \begin{figure}[!ht]
    \centering
    \subfigure[Exemplo do que ocorre com o conjunto de treino durante as iterações do BDT]{
      \includegraphics[width=8cm]{images/bdt_example.png}
      \label{fig:bdt_example}
    }
    \subfigure[O resultado final é por voto majoritário.]{
      \includegraphics[width=8cm]{images/bdt_result.png}
      \label{fig:bdt_result}
    }
    \caption{Ilustração do método BDT. Baseado em~\cite{Duda:2000:PC:954544}.}
    \label{bdt_training}
  \end{figure}
