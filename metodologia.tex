\chapter{Metodologia}
\label{metodologia}
Este capítulo descreve o processo de estudo utilizado para este mestrado. 

As seções~\ref{dataset} e~\ref{selection} descrevem, respectivamente, o conjunto de dados adquiridos e os atributos que foram previamente selecionados; A seção~\ref{ensemble} descreve os algoritmos de máquina de aprendizado utilizados;

    \section{Base de dados}
    \label{dataset}
    O Tile-in-ONE encontra-se em produção, sendo utilizado pelos grupos de calibração e qualidade de dados do TileCal desde 2014. Em seu banco de dados, existe um total de 512 códigos de Plugins, desenvolvidos pelos colaboradores através da plataforma web. A figura~\ref{fig:developed_source_codes} corresponde a quantidade de códigos fonte implementados no período de Junho de 2014 a Dezembro de 2015.

    \begin{figure}[H]
      \centering
      \includegraphics[width=17cm]{images/total_source_codes.png}
      \caption{Total de códigos fonte escritos (512) entre Junho/2014 e Dezembro/2015.}
      \label{fig:developed_source_codes}
    \end{figure}

    Dos 512 códigos que compõem o conjunto de dados, quase 30\% não obtiveram sucesso ao serem enviados para uma máquina \emph{slave}. De acordo com a figura~\ref{fig:slave_machine_results}, percebe-se que 8,59\% não retornaram nenhum tipo de resposta para o servidor principal, o que pode significar que a máquina \emph{slave} escolhida para executar o código fonte em questão estava sem comunicação. Isso não significa necessariamente que o código fonte é \emph{não executável}, uma vez que ele nem sequer chegou na máquina \emph{slave}. Os 21,09\% restantes correspondem a programas que falharam durante a tentativa de execução. Mas novamente, não é possível afirmar neste momento que tais códigos são \emph{não executáveis}. Se por ventura, algum desses tentou acessar um banco de dados (externo a plataforma) que no momento da execução estava inacessível, a máquina \emph{slave} retornou falha e, neste caso, o problema não foi o código fonte. Talvez no futuro, esse tipo de informação possa se tornar uma entrada para o classificador: caso o código fonte esteja acessando uma fonte externa ele pode ser penalizado.

    \begin{figure}[H]
      \centering
      \includegraphics[width=8cm]{images/slave_machines_results.png}
      \caption{Retornos obtidos após tentativa de executar códigos fonte em máquinas \emph{slave}.}
      \label{fig:slave_machine_results}
    \end{figure}

    Após avaliar os 512 códigos, e comparar com a aplicação do analisador estático (PyLint), percebe-se que 82,02\% dos códigos são \emph{executáveis}, mas em quase 20\% dos casos o PyLint gera algum tipo de alerta. Do restante, menos de 1\% é \emph{não executável} devido a erros de sintaxe em Python, mas podem ser facilmente identificados ao executar o analisador estático. Dos outros quase 17\% \emph{não executáveis}, cerca de 5\% não podem ser identificados apenas com a aplicação do Pylint. A figura~\ref{fig:targets} ilustra esses percentuais.

    \begin{figure}[H]
      \centering
      \includegraphics[width=8cm]{images/targets.png}
      \caption{Percentuais de alvos do conjunto de códigos fonte.}
      \label{fig:targets}
    \end{figure}

    Em suma, a aplicação do analisador estático não é suficiente para classificar um código como \emph{executável} ou \emph{não executável}. Uma ferramenta adicional faz-se necessária.

    \section{Análise de atributos}
    \label{selection}
    A tabela~\ref{tab:initialattributes} descreve os 11 atributos inicialmente extraídos dos códigos fonte disponíveis na base de dados da plataforma Tile-in-ONE. Ao gerar a matriz de correlação entre tais atributos (figura~\ref{fig:initialcorrelation}), percebe-se que os atributos relacionados às medidas e estatísticas de Halstead são fortemente correlacionados.

    \begin{figure}[H]
      \centering
      \includegraphics[width=10cm]{images/corr_matrix_11.png}
      \caption{Matriz de correlação dos 11 atributos extraídos inicialmente}
      \label{fig:initialcorrelation}
    \end{figure} 

    O teste $\chi^2$ foi aplicado para entender, dentre os atributos relacionados a Halstead, quais são os dois mais relevantes. Em outras palavras, dentre os atributos correlacionados, deseja-se utilizar os dois mais independentes, segundo o teste $\chi^2$. Para este caso, os atributos vencedores são: \emph{Halstead Volume} e \emph{Required Time}. A nova matriz de correlação calculada (figura~\ref{fig:finalattributes}) demonstra que os 6 atributos selecionados (tabela~\ref{tab:finalattributes}) são suficientemente independentes entre si (com exceção das medidas de Halstead). Observa-se ainda a independência dos atributos selecionados com o alvo, como ilustrado na figura~\ref{fig:finalattributes}.

    \begin{table}[]
    \centering
    \caption{Lista de atributos selecionados}
    \label{tab:finalattributes}
    \begin{tabular}{@{}|l|c|l|@{}}
    \toprule
    \multicolumn{1}{|c|}{\textbf{\#}} & \textbf{Atributo}                       & \multicolumn{1}{c|}{\textbf{Descrição}}                            \\ \midrule
    1                                 & Complexidade Ciclomática                & Número de declarações                                              \\ \midrule
    2                                 & Índice de Manutenabilidade              & Corresponde à organização do código                                \\ \midrule
    3                                 & \multicolumn{1}{l|}{Volume de Halstead} & Combinação entre número de linhas e declarações                    \\ \midrule
    4                                 & Tempo de Halstead                       & Tempo estimado para compilar um código                             \\ \midrule
    5                                & LLOC                                    & Número de linhas lógicas                                           \\ \midrule
    6                                & Alertas PyLint                          & \begin{tabular}[c]{@{}l@{}}Verdadeiro se PyLint gerou alertas. \\ Caso contrário, falso\end{tabular}\\ \bottomrule
    \end{tabular}
    \end{table}

    \begin{figure}[H]
      \centering
      \includegraphics[width=10cm]{images/finalattributes.png}
      \caption{Matriz de correlação dos 6 atributos selecionados. As correlações com a saída também são calculadas.}
      \label{fig:finalattributes}
    \end{figure} 

    \section{Classificadores em \emph{ensemble}}
    \label{training}

    Em Física de Altas Energias, é comum encontrar a aplicação de BDT (\emph{Boosted Decision Tree}, ver seção~\ref{bdt}) para identificação de partículas. No Farmilab, por exemplo, as análises para busca de oscilações de neutrinos deu-se por meio de aplicação de BDT~\cite{Roe2005577}. No CERN existem diversos trabalhos utilizando BDT para identificação do Bóson de Higgs. Portanto, existe um incentivo natural para a aplicação de métodos \emph{ensemble} com árvores neste projeto contextualizado no ambiente do CERN. Como citado, a popularidade de árvores de decisão na comunidade científica vem da sua fácil compreensão.

    Com os atributos selecionados (seção~\ref{selection}), classificadores em \emph{ensemble} foram treinados. Para todos os casos, o algoritmo base é uma árvore de decisão, gerada previamente. O objetivo em se treinar mais de um classificador é avaliar se o problema a ser resolvido tem solução. Como saídas, teremos as classes \emph{executável} indicando que provavelmente o código fonte não vai falhar ao ser executado na máquina \emph{slave} ou, caso contrário, \emph{não executável}.

    Antes de dividir o conjunto de dados em subconjuntos de treino (70\%) e teste (30\%), foi necessário replicar o conjunto com alvo \emph{não executável}, devido a desproporção em número de amostras. É importante ressaltar que os mesmos conjuntos de treino e teste foram utilizados para todos os casos.

    Como avaliação de performance, foram avaliadas as matrizes de confusão e os F1-scores. Em análises estatísticas de classificação binária, o F1-score é uma medida de acurácia. Ela considera tanto precisão quanto sensibilidade, como pode ser observado pela fórmula abaixo:

    \begin{center}
    $F1_{score} = 2 . \frac{p . r}{p + r}$
    \end{center}
    , onde $p$ é precisão e $r$ é sensibilidade.

    Precisão é o número de verdadeiro positivos dividido pelo número total de resultados positivos. Sensibilidade é o número de verdadeiro positivos dividido pelo número de resultados positivos que deveriam ter sido retornados.

    O F1-score pode ser interpretado como uma média ponderada da precisão e sensibilidade, onde o melhor valor para avaliar a acurária é 1 e o pior, 0.
    \\ \\
    \textbf{\large{Árvore de decisão}}\\ \\
    O critério \emph{gini} para divisão da árvore de decisão foi utilizado. Estipulou-se um tamanho máximo igual a três, a fim de evitar \emph{overfitting}. O esperado é que este classificador tenha uma acurácia pior do que os demais. Esta árvore foi utilizada como classificador base nos três métodos \emph{ensemble} utilizados descritos a seguir. 
    \\ \\
    \textbf{\large{Bagged Trees}}\\ \\
    Utilizando o mesmo conjunto de treino utilizado para treinar o classificador base e, utilizando a árvore de decisão descrita anteriormente, um classificador em \emph{Bagged Tree} foi gerado. No caso, o número de iterações estabelecido é igual a 100. Ou seja, ao final do treinamento, tem-se 100 árvores treinadas. O resultado dá-se por voto majoritário dessas 100 árvores. A cada rodada, 10\% do conjunto de treino foi utilizado como sub-conjunto \emph{boostrap} (o equivalente a cerca de 60 amostras). Isso é o suficiente para garantir que as amostras não sejam repetidas inúmeras vezes, o que mantém a independência dos 100 classificadores gerados pelo método.\\ \\
    \textbf{\large{Random Forest}}\\ \\
    Para o classificador em \emph{Random Forest} os mesmos critérios estabelecidos para treinar o \emph{Bagged Tree} se aplicam. Mas, o que difere os dois métodos é a quantidade de atributos utilizados em cada iteração para treinar uma árvore. Em~\cite{Breiman:2001:RF:570181.570182}, o Breiman avalia que empiricamente, um número de atributos próximo a $\sqrt{N}$ (sendo N o número total de atributos) é suficiente para obter melhor acurácia. No caso abordado nesta dissertação, temos um número de atributos pequeno (e igual a 6), de tal forma que $\sqrt{6} = 2.45$. O número de atributos, então, utilizado para treinar o classificador em \emph{Random Forest} é igual a 3. Como o \emph{OOB error} é calculado a cada iteração, uma análise de relevância de atributos também pode ser extraída durante o treinamento deste classificador.\\ \\
    \textbf{\large{Boosted Decision Trees}}\\ \\
    Para treinar o classificador BDT o mesmo conjunto de treino foi utilizado. Existem diversos algoritmos que determinam como os pesos que serão atribuídos às amostras erroneamente classificadas em cada iteração são definidos. No caso, o algoritmo \emph{AdaBoost}~\cite{Freund1997} (do inglês, \emph{Adaptative Boosting}) foi utilizado. Inicialmente, os pesos atribuídos equivalem a 1. A cada iteração o percentual de amostras classificadas de maneira equivocada é calculado e o peso que será atribúido a tais amostras é definido baseado neste percentual. O resultado final dependerá também deste peso calculado a cada iteração.

    A figura~\ref{fig:adaboost_pseudocode} ilustra um pseudo-código extraído de~\cite{Freund1997}. Nela é possível entender como o peso $\beta$ é calculado, e também como o resultado final é obtido.

    \begin{figure}[H]
      \centering
      \includegraphics[width=8cm]{images/bdt_pseudocode.png}
      \caption{Pseudo-código do algoritmo \emph{AdaBoost}}
      \label{fig:adaboost_pseudocode}
    \end{figure} 